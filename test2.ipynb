{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfd140ec-3523-462c-be25-4714ec629410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5c49031-2613-487f-9408-e0fb59b00e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = 128\n",
    "input_shape = (img_shape, img_shape, 3)\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "295fa601-1135-41b1-bb4d-4f8785375053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = tf.strings.split(file_path, os.path.sep)[-2]\n",
    "    label_arr = None\n",
    "    if label == 'fake':\n",
    "        label_arr = 0\n",
    "    else:\n",
    "        label_arr = 1\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img, [img_shape, img_shape])\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return (img, label_arr)\n",
    "\n",
    "def scale(image, label):\n",
    "    return (image / 255, label)\n",
    "\n",
    "train_ds = tf.data.Dataset.list_files('1frame/train/*/*')\n",
    "test_ds = tf.data.Dataset.list_files('1frame/test/*/*')\n",
    "val_ds = tf.data.Dataset.list_files('1frame/valid/*/*')\n",
    "\n",
    "train_size = len(train_ds)\n",
    "val_size = len(val_ds)\n",
    "\n",
    "train_ds = train_ds.shuffle(train_size).map(process_path, num_parallel_calls = tf.data.AUTOTUNE).map(scale, num_parallel_calls = tf.data.AUTOTUNE).batch(BATCH_SIZE).repeat(EPOCHS).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.shuffle(val_size).map(process_path, num_parallel_calls = tf.data.AUTOTUNE).map(scale, num_parallel_calls = tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.shuffle(val_size).map(process_path, num_parallel_calls = tf.data.AUTOTUNE).map(scale, num_parallel_calls = tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e37e7b0-8227-41d9-a187-8ff4c6d3d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionResNetV2, EfficientNetB0, ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Input, LeakyReLU, Concatenate\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout, TimeDistributed, LSTM\n",
    "from tensorflow.keras.layers import InputLayer, Rescaling\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52cf5356-fa25-42dd-9578-109e99623c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(include_top = False, weights = 'imagenet', input_shape = input_shape)\n",
    "resnet.trainable = True\n",
    "model = Sequential()\n",
    "model.add(resnet)\n",
    "model.add(Dense(units = 16, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 8, activation = 'relu'))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 8, activation = 'relu'))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2626a8df-18ad-4252-930e-1e9234f29bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4, 4, 16)          32784     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4, 4, 8)           136       \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 23,704,105\n",
      "Trainable params: 23,650,985\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.Adam(learning_rate = 1e-3), metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc5da1-9acc-43b2-8f20-846a0584314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4894/4894 [==============================] - 574s 116ms/step - loss: 0.6187 - accuracy: 0.6562 - val_loss: 0.6365 - val_accuracy: 0.6543\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63647, saving model to checkpoints\\best_1fdfd_resnet_lstm_dfdc.hdf5\n",
      "Epoch 2/10\n",
      "4894/4894 [==============================] - 604s 123ms/step - loss: 0.5163 - accuracy: 0.7477 - val_loss: 0.6275 - val_accuracy: 0.6712\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63647 to 0.62750, saving model to checkpoints\\best_1fdfd_resnet_lstm_dfdc.hdf5\n",
      "Epoch 3/10\n",
      "4894/4894 [==============================] - 602s 123ms/step - loss: 0.3856 - accuracy: 0.8311 - val_loss: 0.9119 - val_accuracy: 0.5652\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.62750\n",
      "Epoch 4/10\n",
      "4894/4894 [==============================] - 544s 111ms/step - loss: 0.2872 - accuracy: 0.8886 - val_loss: 1.0227 - val_accuracy: 0.5543\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.62750\n",
      "Epoch 5/10\n",
      "4894/4894 [==============================] - 533s 109ms/step - loss: 0.2351 - accuracy: 0.9144 - val_loss: 1.4597 - val_accuracy: 0.5082\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.62750\n",
      "Epoch 6/10\n",
      "4894/4894 [==============================] - 533s 109ms/step - loss: 0.1750 - accuracy: 0.9405 - val_loss: 1.1522 - val_accuracy: 0.5565\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.62750\n",
      "Epoch 7/10\n",
      "2003/4894 [===========>..................] - ETA: 5:03 - loss: 0.1555 - accuracy: 0.9468"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath = 'checkpoints/best_1fdfd_resnet_lstm_dfdc.hdf5',\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 1,\n",
    "    save_best_only = True,\n",
    "    mode = 'min')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                              factor = 0.2,\n",
    "                              patience = 3, \n",
    "                              min_lr = 0.0001)\n",
    "\n",
    "STEPS = train_size // BATCH_SIZE\n",
    "callbacks = [checkpoint_callback, reduce_lr]\n",
    "history = model.fit(train_ds, batch_size = BATCH_SIZE, steps_per_epoch = STEPS, epochs = EPOCHS, callbacks = callbacks, validation_data = val_ds, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f28945-8082-4564-96e0-09bcc3524d79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('models/resnet_lstm_dfd_model_1fdfd')\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 4))\n",
    "t = f.suptitle('EfficientNetB0 with LSTM on Kaggle Dataset', fontsize = 12)\n",
    "f.subplots_adjust(top = 0.85, wspace = 0.3)\n",
    "\n",
    "epoch_list = list(range(1, EPOCHS + 1))\n",
    "ax1.plot(epoch_list, history.history['accuracy'], label = 'Train Accuracy')\n",
    "ax1.plot(epoch_list, history.history['val_accuracy'], label = 'Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, EPOCHS + 1, 1))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch #')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label = 'Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label = 'Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, EPOCHS + 1, 1))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch #')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189e77f-a598-4073-890b-c4b745b82ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_ds)\n",
    "print(model.metrics_names)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125004f4-2f95-487e-b905-37962d9bed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output confusion matrix\n",
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('True positive = ', cm[0][0])\n",
    "    print('False positive = ', cm[0][1])\n",
    "    print('False negative = ', cm[1][0])\n",
    "    print('True negative = ', cm[1][1])\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "    plt.ylabel('Actual label', size = 20)\n",
    "    plt.xlabel('Predicted label', size = 20)\n",
    "    plt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.ylim([2, 0])\n",
    "    plt.show()\n",
    "    \n",
    "print_confusion_matrix(Y_val_org, np.argmax(model.predict(X),axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
